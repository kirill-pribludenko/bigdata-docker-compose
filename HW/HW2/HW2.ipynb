{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dec5bf8-6865-417a-9aac-420908e9afda",
   "metadata": {},
   "source": [
    "# 1. Spark application (70 баллов в сумме)\n",
    "* Развернуть hadoop-кластер в конфигурации 1 namenode, 1 datanode, 1 resourcemanager, 1 nodemanager. Также развернуть jupyter в контейнере (все перечисленное уже есть в docker-compose (https://github.com/smalyshevv/bigdata-docker-pyspark)) (30 баллов)\n",
    "* Запустить спарк-сессию (SparkSession) с мастером YARN, 2-мя экзекьюторами и именем приложения “{фамилия}_spark”- перед этим обязательно выйдите из savemode в hdfs (hdfs dfsadmin -safemode leave). Приложить скрин YARN-а, где запущено приложение, приложить скрин UI приложения spark (30 баллов) \n",
    "* Прочитать таблицы ratings, tags в директории ml-latest-small; отобразить количество строчек и в том, и в другом датасете. (Не забудьте перекинуть ваши данные из контейнера jupyter в hdfs: \n",
    "hdfs dfs -rm -r ml-latest-small - это на всякий случай, если будете перезапускать контейнеры\n",
    "hdfs dfs -put ml-latest-small .\n",
    "Приложить скрин spark-ui с выполненной job-ой (можно приложить прям в markdown ячейки, можно положить в той же папке, что и ноутбук). Написать, сколько было выполнено стейджей и тасок. (10 баллов)\n",
    "* В качестве результата приложите ноутбук с названием hw_spark в папке notebooks и кодом созданной спарк-сессии, скринами, и прочитанными датасетами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146c65bf-583b-4930-9fe1-5fe09a670164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтобы не было в винде ошибки /opt/hadoop/etc/hadoop/hadoop-env.sh: line 127: $'\\r': command not found\n",
    "# Запустить один раз\n",
    "!sed -i 's/\\r$//' /opt/hadoop/etc/hadoop/hadoop-env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3622bb18-5061-48e3-8be7-bf2ec48f7dfb",
   "metadata": {},
   "source": [
    "Установка и импорты библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5deb255e-6b6f-4a5f-89ac-daac06479f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe mode is OFF\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfsadmin -safemode leave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658b8e4a-9fa6-4393-aaf3-69e39e64ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8784882-6ac1-47a8-877b-64f6cd6f996d",
   "metadata": {},
   "source": [
    "Создание сессии и загрузка датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7e0a8fc-3489-42f9-b94d-84ae8808130e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/14 10:44:36 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf()\\\n",
    "    .set(\"spark.executor.instances\", \"2\")\\\n",
    "    .set(\"spark.executor.cores\", \"1\")\\\n",
    "    .set(\"spark.executor.memory\", \"1g\")\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).master(master=\"yarn\").appName(\"Pribludenko_spark\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87d111f6-baf5-4739-847c-25285c5a97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put: `ml-latest-small/links.csv': File exists\n",
      "put: `ml-latest-small/movies.csv': File exists\n",
      "put: `ml-latest-small/ratings.csv': File exists\n",
      "put: `ml-latest-small/README.txt': File exists\n",
      "put: `ml-latest-small/tags.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -put notebooks/ml-latest-small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f54a2-ca66-41de-82aa-66dad63a5a4e",
   "metadata": {},
   "source": [
    "Чтение датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39b47f4-6f66-4377-b751-0b17e8528fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c040e1-7ef8-4495-b662-d73c6aeb2e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во строк 100836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ratings_schema = StructType(fields=[\n",
    "    StructField(\"userId\", IntegerType()),\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"rating\", DoubleType()),\n",
    "    StructField(\"timestamp\", LongType()),\n",
    "])\n",
    "\n",
    "ratings_df = spark\\\n",
    "    .read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", \"True\")\\\n",
    "    .schema(ratings_schema)\\\n",
    "    .load(\"ml-latest-small/ratings.csv\")\n",
    "\n",
    "print('Кол-во строк',ratings_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e7fcf2-55dc-4cc4-93ed-cf51c97042aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во строк 3683\n"
     ]
    }
   ],
   "source": [
    "tags_schema = StructType(fields=[\n",
    "    StructField(\"userId\", IntegerType()),\n",
    "    StructField(\"movieId\", IntegerType()),\n",
    "    StructField(\"tag\", StringType()),\n",
    "    StructField(\"timestamp\", LongType()),\n",
    "])\n",
    "\n",
    "tags_df = spark\\\n",
    "    .read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"header\", \"True\")\\\n",
    "    .schema(tags_schema)\\\n",
    "    .load(\"ml-latest-small/tags.csv\")\n",
    "\n",
    "print('Кол-во строк', tags_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb072b-1e04-47b9-b2ae-ad7d726d6f7f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e5804-3632-4ef4-adad-64a2f1d61ad0",
   "metadata": {},
   "source": [
    "# 2. Работа с данными (30 баллов в сумме)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e61663-9a82-4be1-96e5-2a4c1ec9177e",
   "metadata": {},
   "source": [
    "* Посчитать количество уникальных фильмов и уникальных юзеров в таблице “ratings”. (5 баллов)\n",
    "* Посчитать, сколько было поставлено оценок >= 4.0. (5 баллов)\n",
    "* Вывести топ100 фильмов с самым высоким рейтингом. (6 баллов)\n",
    "* Посчитать разницу во времени в секундах между временем тегирования пользователя данного фильма и временем, когда пользователь поставил оценку фильму. В качестве ответа выведете среднюю дельту по времени. (7 баллов)\n",
    "* Посчитать среднюю оценку от каждого пользователя, в качестве ответа выведете среднее от всех усредненных оценок всех пользователей. (7 баллов)\n",
    "* Результаты должны быть в том же ноутбуке из прошлого пункта и написаны на pyspark-методах без toPandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e9b50-e20e-44a6-8b73-cc18e944ef4c",
   "metadata": {},
   "source": [
    "## Посчитать количество уникальных фильмов и уникальных юзеров в таблице “ratings”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a133628-bd3b-4333-9982-924de2b7af04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT movieId)|\n",
      "+-----------------------+\n",
      "|                   9724|\n",
      "+-----------------------+\n",
      "\n",
      "+----------------------+\n",
      "|count(DISTINCT userId)|\n",
      "+----------------------+\n",
      "|                   610|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "# Фильмы\n",
    "unique_movies = ratings_df.select(countDistinct(\"movieId\")).alias(\"unique_movies\")\n",
    "unique_movies.show()\n",
    "\n",
    "# Пользователи\n",
    "unique_users = ratings_df.select(countDistinct(\"userId\")).alias(\"unique_users\")\n",
    "unique_users.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0e1c5-fb95-41d3-ac0b-c4101bc82ba5",
   "metadata": {},
   "source": [
    "## Посчитать, сколько было поставлено оценок >= 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a6b130-c846-417b-8400-18b99771b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во оценок >= 4.0: 48580\n"
     ]
    }
   ],
   "source": [
    "highly_rated_movies = ratings_df.filter(ratings_df[\"rating\"] >= 4.0).count()\n",
    "print(\"Кол-во оценок >= 4.0:\", highly_rated_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2057ce-749b-439c-b986-845ad1d23771",
   "metadata": {},
   "source": [
    "## Вывести топ100 фильмов с самым высоким рейтингом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735b7224-3758-45cc-a1cf-4cc5aecf1237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|movieId|average_rating|\n",
      "+-------+--------------+\n",
      "|  26350|           5.0|\n",
      "|   3795|           5.0|\n",
      "|  25887|           5.0|\n",
      "| 157775|           5.0|\n",
      "|    633|           5.0|\n",
      "|  33138|           5.0|\n",
      "|  67618|           5.0|\n",
      "|    876|           5.0|\n",
      "|    496|           5.0|\n",
      "|  27373|           5.0|\n",
      "| 113829|           5.0|\n",
      "|  53578|           5.0|\n",
      "| 152711|           5.0|\n",
      "| 118894|           5.0|\n",
      "|     53|           5.0|\n",
      "| 160644|           5.0|\n",
      "|    148|           5.0|\n",
      "|   8911|           5.0|\n",
      "| 147300|           5.0|\n",
      "|  84273|           5.0|\n",
      "+-------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, col\n",
    "\n",
    "top_100_movies = ratings_df.groupBy(\"movieId\").agg(avg(\"rating\").alias(\"average_rating\"))\n",
    "top_100_movies = top_100_movies.orderBy(col(\"average_rating\").desc()).limit(100)\n",
    "top_100_movies.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4a7cc-1d01-44c9-9d8a-fde7f193a1fc",
   "metadata": {},
   "source": [
    "## Посчитать разницу во времени в секундах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ca5ab57-906d-4de3-8b8a-ead8bdfd855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      avg(time_diff)|\n",
      "+--------------------+\n",
      "|2.9203715568469506E7|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import abs\n",
    "\n",
    "tag_and_rating = tags_df.join(ratings_df, [\"userId\", \"movieId\"])\n",
    "\n",
    "time_diff = tag_and_rating.select(abs(tags_df['timestamp'] - ratings_df['timestamp']).alias(\"time_diff\"))\n",
    "avg_time_diff = time_diff.select(avg(\"time_diff\"))\n",
    "avg_time_diff.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9fa156-f8bd-4b52-853c-47b3f86f7c33",
   "metadata": {},
   "source": [
    "## Посчитать среднюю оценку от каждого пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd5ebd10-a4e7-4ef0-9c35-98e97f548f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   avg(avg_rating)|\n",
      "+------------------+\n",
      "|3.6572223377474016|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_avg_rating = ratings_df.groupBy(\"userId\").agg(avg(\"rating\").alias(\"avg_rating\"))\n",
    "\n",
    "overall_avg_rating = user_avg_rating.select(avg(\"avg_rating\"))\n",
    "overall_avg_rating.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36379eff-746e-47b9-af4e-3524e79405f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e476fef-652e-453a-bcf9-bd71dabf1b40",
   "metadata": {},
   "source": [
    "# 3. UDF (25 баллов в сумме)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffc191-0aa5-43d2-9b9f-1174ded874e7",
   "metadata": {},
   "source": [
    "* Обучите модель предсказания оценок по тегам с помощью TfidfVectorizer и SGDRegressor из модуля scikit-learn - тут уже можно сконвертировать два датасета в pandas через .toPandas\n",
    "    * сначала  TfidfVectorizer обучаете на колонке “tag”\n",
    "    * получаете численные признаки transform-ом от tfidf на той же колонке “tag”\n",
    "    * обучаете SGDRegressor на новых численных признаках от  TfidfVectorizer-а с лейблом “rating”\n",
    "* Напишите UDF, которая делает предсказание рейтинга по столбцу “tag”\n",
    "    * сначала transform от TfidfVectorizer\n",
    "    * затем predict от SGDRegressor на полученных признаках из 1 этапа\n",
    "* Примените UDF к spar-dataframe-у и убедитесь, что udf работает (можно вызвать какой нибудь action, например show(50)). Приложите скрин дага вычислений этой джобы в spark-ui. (15 баллов)\n",
    "* Напишите, чему равен корень суммы квадратов разностей (RMSE) между предсказанным и истинным значением рейтинга (напишите это на pyspark-е). *Напишите, сколько было выполнено стейджей и тасок в рамках джобы. (10 баллов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf64cbd0-86f8-48cf-aa95-857a5c2b54d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Конвертация в пандас дф\n",
    "tags_pd = tags_df.toPandas()\n",
    "ratings_pd = ratings_df.toPandas()\n",
    "\n",
    "# TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(tags_pd['tag'])\n",
    "\n",
    "# Подготовка данных SGDRegressor\n",
    "X = tfidf_matrix\n",
    "y = tags_pd.merge(ratings_pd.groupby(['movieId'])['rating'].mean(), on='movieId', how='left')['rating']\n",
    "y = y.fillna(y.mean())\n",
    "\n",
    "# Обучение SGDRegressor\n",
    "sgd = SGDRegressor()\n",
    "sgd.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b72ffec-e396-4c65-be38-c66fa5efedc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------------------+----------+----------------+\n",
      "|userId|movieId|                 tag| timestamp|predicted_rating|\n",
      "+------+-------+--------------------+----------+----------------+\n",
      "|     2|  60756|               funny|1445714994|        3.990981|\n",
      "|     2|  60756|     Highly quotable|1445714996|       3.3995721|\n",
      "|     2|  60756|        will ferrell|1445714992|       3.6068056|\n",
      "|     2|  89774|        Boxing story|1445715207|       3.9034495|\n",
      "|     2|  89774|                 MMA|1445715200|        3.068867|\n",
      "|     2|  89774|           Tom Hardy|1445715205|       3.4618847|\n",
      "|     2| 106782|               drugs|1445715054|        3.807145|\n",
      "|     2| 106782|   Leonardo DiCaprio|1445715051|       3.8281453|\n",
      "|     2| 106782|     Martin Scorsese|1445715056|       3.4350429|\n",
      "|     7|  48516|        way too long|1169687325|       3.4251742|\n",
      "|    18|    431|           Al Pacino|1462138765|       3.4118843|\n",
      "|    18|    431|            gangster|1462138749|       3.2631786|\n",
      "|    18|    431|               mafia|1462138755|       3.8929472|\n",
      "|    18|   1221|           Al Pacino|1461699306|       3.4118843|\n",
      "|    18|   1221|               Mafia|1461699303|       3.8929472|\n",
      "|    18|   5995|           holocaust|1455735472|       3.9449124|\n",
      "|    18|   5995|          true story|1455735479|       3.6695778|\n",
      "|    18|  44665|        twist ending|1456948283|        4.260562|\n",
      "|    18|  52604|     Anthony Hopkins|1457650696|       3.0669749|\n",
      "|    18|  52604|     courtroom drama|1457650711|       3.3995533|\n",
      "|    18|  52604|        twist ending|1457650682|        4.260562|\n",
      "|    18|  88094|             britpop|1457444500|       3.0195653|\n",
      "|    18|  88094|  indie record label|1457444592|       3.0199213|\n",
      "|    18|  88094|               music|1457444609|       3.9477215|\n",
      "|    18| 144210|     dumpster diving|1455060381|       3.0878122|\n",
      "|    18| 144210|      Sustainability|1455060452|       3.0869586|\n",
      "|    21|   1569|     romantic comedy|1419805413|       3.7877192|\n",
      "|    21|   1569|             wedding|1419805419|        3.343206|\n",
      "|    21| 118985|             painter|1419805477|       3.0720737|\n",
      "|    21| 119141|              bloody|1419793962|       3.3408139|\n",
      "|    49| 109487|          black hole|1493093306|       3.4967852|\n",
      "|    49| 109487|              sci-fi|1493093332|       4.1452036|\n",
      "|    49| 109487|         time-travel|1493093356|        4.006938|\n",
      "|    62|      2|             fantasy|1528843929|       3.6956851|\n",
      "|    62|      2|    magic board game|1528843932|        3.402707|\n",
      "|    62|      2|      Robin Williams|1528843907|       3.3026996|\n",
      "|    62|    110|   beautiful scenery|1528152541|       3.6025343|\n",
      "|    62|    110|                epic|1528152532|       3.5883074|\n",
      "|    62|    110|          historical|1528152523|         3.08993|\n",
      "|    62|    110|       inspirational|1528152527|        3.647038|\n",
      "|    62|    110|            Medieval|1528152528|       3.0969863|\n",
      "|    62|    110|          mel gibson|1528152521|        3.160759|\n",
      "|    62|    110|Oscar (Best Cinem...|1528152539|        3.977289|\n",
      "|    62|    110|             revenge|1528152531|       3.7069583|\n",
      "|    62|    110|         sword fight|1528152535|       3.0894918|\n",
      "|    62|    410|        black comedy|1525636607|       4.1835704|\n",
      "|    62|    410|     Christina Ricci|1525636685|        3.096548|\n",
      "|    62|    410|   Christopher Lloyd|1525636622|       3.3208523|\n",
      "|    62|    410|         dark comedy|1525636610|       4.4078026|\n",
      "|    62|    410|              family|1525636708|       3.5630934|\n",
      "+------+-------+--------------------+----------+----------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "def predict_tag_rating(tag):\n",
    "    # Трансофрмация и предикт\n",
    "    tfidf_features = tfidf.transform([tag])\n",
    "    prediction = sgd.predict(tfidf_features)[0]\n",
    "    return float(prediction)\n",
    "\n",
    "# UDF функция\n",
    "predict_rating_udf = F.udf(predict_tag_rating, FloatType())\n",
    "\n",
    "# Применение UDF функции\n",
    "tags_df_with_predictions = tags_df.withColumn(\"predicted_rating\", predict_rating_udf(F.col(\"tag\")))\n",
    "tags_df_with_predictions.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e3a5ce1-03c7-41ec-b693-0413adb7d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|              rmse|\n",
      "+------------------+\n",
      "|1.0233588979711892|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sqrt\n",
    "\n",
    "# джойним таблички\n",
    "df_with_true_ratings = tags_df_with_predictions.join(ratings_df, [\"userId\", \"movieId\"], \"inner\")\n",
    "\n",
    "# Считаем RMSE\n",
    "rmse = df_with_true_ratings.select(sqrt(avg((col(\"rating\") - col(\"predicted_rating\"))**2)).alias(\"rmse\"))\n",
    "rmse.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a62300-d06a-4c91-b700-882994c7c854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
